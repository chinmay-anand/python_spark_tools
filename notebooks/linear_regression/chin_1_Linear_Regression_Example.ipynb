{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFER Chapter 2 and 3 of \"Introduction to Stastical Learning\" by Gareth James"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pyspark API Documentation:\n",
    "* http://spark.apache.org/docs/latest/\n",
    "* http://spark.apache.org/docs/latest/ml-guide.html\n",
    "* https://spark.apache.org/docs/latest/api/python/\n",
    "\n",
    "## [Introduction to Statistical Learning](<https://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files to open in browser: \n",
    "    * Documentation Page for Linear Regression\n",
    "    * Data from Documentation: \n",
    "    * Linear_Regression_Example.ipynb\n",
    "    * New Untitled Notebook: for my experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Spark Documentation Example Page for Linear Regression\n",
    "* http://spark.apache.org/docs/latest/ml-guide.html\n",
    "* How to reach there\n",
    "> http://spark.apache.org/docs/latest/ --> Programming Guide --> MLlib (Machine Learning) --> http://spark.apache.org/docs/latest/ml-guide.html --> Classification and Regression --> Linear Regression --> Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enable the shell to print multiple results (instead of only the last result)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### import chinmay_tools for various utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/nishita/exercises_udemy')\n",
    "from tools.chinmay_tools import printHighlighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printHighlighted('STEPs for training testing and deploying using LinearRegression model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Train-Validate-Deploy a LinearRegression model\n",
    "#### STEPS PERFORMED BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initiated a spark session to start work. SparkSession.build.appName('test')<b>.getOrCreate</b>()\n",
    "* Created an instance of the model e.g. LinearRegression() with specific parameters supplied.\n",
    "* Loaded the data from file into a dataframe (say \"all_data\") [sparkSesn.read<b>.format('libsvm').load</b>(fileName)]\n",
    "    * We could read using .read.text(file) instead of .read.format..load(file), BUT .format() version is more generic.\n",
    "    * Sometimes the .format('libsvm').load(fileName) fails, then use \".format('libsvm').option('numFeatures',10),load(fileName)\n",
    "        * Reason: there are 10 features in the text file (open and check it), so set numFeatures option to 10\n",
    "* Splitted the data (in proportion of n1:n2) into train_data and test_data using dataframe<b>.randomSplit([n1,n2])</b> method. We used n1=0.7 and n2=0.3\n",
    "* Trained our model with the train_data (proportion n1) using trained_model = our_model<b>.fit</b>(train_data) result is of type LinearRegressionModel, where as instantiated model was of type LinearRegression\n",
    "* Then comared the trained model (result of our_model.fit ) against the test data using trained_model<b>.evaluate</b>(test_data). Used metods like .r2, .rootMeanSquaredError, 'residual etc on the result from .evaluate\n",
    "    * residuals are actually the difference of the predicted values from the actual values, i.e. the vertical distances of the actual points formt he regression line.\n",
    "* Then we predicted the label on an unlabeled data using our_model<b>.transform()</b>\n",
    "* Basic packages used:\n",
    "    * SparkSession from pyspark.sql\n",
    "    * LinearRegression from pyspark.ml.regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a spark session to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark1 = SparkSession.builder.appName('lr_example').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"display: inline\">Heading 1</h1>\n",
    "<h2 style=\"display: inline\">Heading 2</h2>\n",
    "<h3 style=\"display: inline\">Heading 2</h3>\n",
    "<h4 style=\"display: inline\">Heading 2</h4>\n",
    "<h5 style=\"display: inline\">Heading 2</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Load training data\n",
    "\n",
    "# training = spark.read.format(\"libsvm\").load(\"sample_linear_regression_data.txt\")\n",
    "\n",
    "## The above line works from udemy example folder\n",
    "## But if I copy the file to somewhere else then ot fails with error \"Py4JJavaError: An error occurred while calling o317.load.\"\n",
    "## The above error is avoided by setting \"numFeatures\" in option method Refer: https://stackoverflow.com/questions/59244415/spark-read-formatlibsvm-not-working-with-python\n",
    "### BUT REASON IS NOT CLEAR\n",
    "## Checked the text file and found there 10 features and hence set the option \"numFeatures\" to \"10\". We can even pass higher , but NOT lower than the number of features.\n",
    "\n",
    "training = spark1.read.format(\"libsvm\").option(\"numFeatures\",\"10\").load(\"Linear_Regression/sample_linear_regression_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = spark1.read.format('libsvm').load('sample_linear_regression_data.txt')\n",
    "\n",
    "# printHighlighted(\"Note down the format of 'libsvm', it is similar to csv or json. The 'libsvm' is not well documented.\")\n",
    "training.printSchema()\n",
    "training.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an instance of the algorithm or the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Create an instance of the model\n",
    "lr=LinearRegression(featuresCol='features', labelCol='label', predictionCol='prediction', maxIter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Train the model with the loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lrModel = lr.fit(training)\n",
    "# Here we have fit or trained the model with the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print the deetails and  parameters from the trained model and its summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the details of the model\n",
    "lrModel.coefficients  # print coefficients of the features\n",
    "lrModel.intercept\n",
    "\n",
    "#print the model summary information\n",
    "training_summary = lrModel.summary\n",
    "\n",
    "training_summary.residuals.show()\n",
    "training_summary.rootMeanSquaredError\n",
    "training_summary.meanSquaredError\n",
    "training_summary.meanAbsoluteError\n",
    "training_summary.r2\n",
    "training_summary.totalIterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now load the data again but don't train the model with the entire set of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = spark1.read.format(\"libsvm\").load(\"sample_linear_regression_data.txt\")\n",
    "all_data = spark1.read.format(\"libsvm\").option(\"numFeatures\", 10).load(\"Linear_Regression/sample_linear_regression_data.txt\")\n",
    "#REFER: https://stackoverflow.com/questions/59244415/spark-read-formatlibsvm-not-working-with-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD\n",
    "###### Split the data into training data and test data using randosmsplit() on the dataframe\n",
    "* i.e. Load the train_data with a major portion from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = all_data.randomSplit([0.7, 0.3])    # Data is split into 70% (i.e. 0.7) for train_data and 30% for test_Data into two dataframes\n",
    "\n",
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN\n",
    "###### Train the model with train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the model on the training data\n",
    "correct_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATE\n",
    "###### Now evaluate how the model did on the train_data  by running it on test_data which is not yet seen by the model\n",
    "* Run trained_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = correct_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The .evaluate() on the trained model actually compares our predictions against the labels that were already assigned in the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_result)\n",
    "type(correct_model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.r2\n",
    "test_result.rootMeanSquaredError\n",
    "test_result.residuals.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### How to improve the model to do better predictions\n",
    "* It is a hit and trial method.\n",
    "* Keep testing out with different parameters to the model i.e. in the constructor LinearRegression()..\n",
    "* Explore the other available parameters, keep modifying the used parameters to fine tune \n",
    "* Mess around the parameters to the model constructor and repeat the split, run on train data evaluate against test data\n",
    "* Repeat this till you are comforatable with the result say rootMeanSquaredError etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Once we are comfortable with the resutl we can deploy our model on the unlabeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ensure that there is no label on any of the deployment data\n",
    ">* In other words: The deployment data should be unseen by model and does not have label.\n",
    "* To mimic the production data create a dataframe from the test_data and dropping the \"label\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = test_data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Use .transform() on the model to get our predictions\n",
    "* Note that we used our_model<b>.evaluate()</b> against a labeled but unseen data to compare our predictions against the labels.\n",
    "* our_model<b>.transform()</b> is used to predict labels if there is no model already available in the supplied data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPLOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = correct_model.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lr)\n",
    "type(lrModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
