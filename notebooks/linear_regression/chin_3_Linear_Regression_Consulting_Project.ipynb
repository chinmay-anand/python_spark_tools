{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROJECT BACKGROUND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Requirement: Give accurate estimate of how many crew members a ship will require.\n",
    "    * This information will be passed on by the company to its customers while selleing respective ships to tehm.\n",
    "* The input DataSet fields are: ['Ship Name', 'Cruise Line', 'Age (as of 2013)', 'Tonnage (1000s of tons)', 'passengers (100s)', 'Length (100s of feet)', 'Cabins (100s)', 'Passenger Density', 'Crew (100s)']\n",
    "* create a regression model to predict the number of crew members needed for future ships.\n",
    "* Condition: Particular cruise lines will differ in acceptable crew counts. This may be an important feature as pe Hyundai\n",
    "* Cruise line value is a String value, we need to convert these strings to numbers. We can use STringIndexer from pyspark.ml.feature\n",
    "* Exercise file is: Linear_Regression_Consulting_Project.ipynb and data file is: cruise_line_info.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Consulting Project\n",
    "Congratulations! You've been contracted by Hyundai Heavy Industries to help them build a predictive model for some ships. [Hyundai Heavy Industries](http://www.hyundai.eu/en) is one of the world's largest ship manufacturing companies and builds cruise liners.\n",
    "\n",
    "You've been flown to their headquarters in Ulsan, South Korea to help them give accurate estimates of how many crew members a ship will require.\n",
    "\n",
    "They are currently building new ships for some customers and want you to create a model and use it to predict how many crew members the ships will need.\n",
    "\n",
    "Here is what the data looks like so far:\n",
    "\n",
    "    Description: Measurements of ship size, capacity, crew, and age for 158 cruise\n",
    "    ships.\n",
    "\n",
    "\n",
    "    Variables/Columns\n",
    "    Ship Name     1-20\n",
    "    Cruise Line   21-40\n",
    "    Age (as of 2013)   46-48\n",
    "    Tonnage (1000s of tons)   50-56\n",
    "    passengers (100s)   58-64\n",
    "    Length (100s of feet)  66-72\n",
    "    Cabins  (100s)   74-80\n",
    "    Passenger Density   82-88\n",
    "    Crew  (100s)   90-96\n",
    "    \n",
    "It is saved in a csv file for you called \"cruise_ship_info.csv\". Your job is to create a regression model that will help predict how many crew members will be needed for future ships. The client also mentioned that they have found that particular cruise lines will differ in acceptable crew counts, so it is most likely an important feature to include in your analysis! \n",
    "\n",
    "Once you've created the model and tested it for a quick check on how well you can expect it to perform, make sure you take a look at why it performs so well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enable the shell to print multiple results (instead of only the last result)\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('c:/Users/nishita/exercises_chinmay/tools')\n",
    "from chinmay_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printTextFile('Linear_Regression/cruise_ship_info.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see the contents of the dataset, the second column \"Cruise_line\" is not numeric but affects the crew count. So it is a categorical data point. We can us e StringIndexer to convert it into numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARE THE DATA\n",
    "* Load data from csv\n",
    "* Convert the string field into numeric field using StringIndexer from pyspark.ml.features\n",
    "* Decide on the label column and the feature columns (all numeric)\n",
    "* Create a vectorized combined feature column named 'features'\n",
    "* Get the final input data with two columns 'features' and 'crew' (the label column)\n",
    "* Split the final input dat into training set and test set (70:30 proportion).\n",
    "* NEXT: we will train with train data, evaluate the trained model against test data and print comparison results.\n",
    "* FINALLY: Deploy the model on production data (mimiced from test data after stripping out the label column i.e remvoed 'crew' columns. Compare the prediction results against the residuals of evaluation test result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkEx = SparkSession.builder.appName('cruise_crews').getOrCreate()\n",
    "sdf_cruises = sparkEx.read.csv('Linear_Regression/cruise_ship_info.csv', inferSchema=True, header=True)\n",
    "sdf_cruises.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cruises = getPandasDFfromSparkDF(sdf_cruises)\n",
    "df_cruises.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we will see next, the StringIndexer has converted the \"Cruise_line\" string values into number groups 0,1,2,...etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_cruises.columns\n",
    "sdf_cruises.groupBy('Cruise_line').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert the String data (Cruise_line) into Numeric using StringIndexer\n",
    "* StringIndexer assigns numbers starting from 0 depending on the frequency of occurrence of the associated value in that stirng field\n",
    "* Then we can use that imdexed numeric field as a feature in place of the string field.\n",
    "* As we will see next, the StringIndexer will convert the \"Cruise_line\" string values into number groups 0,1,2,3,...etc and these numerical values can be used by the algorithm instead of a simple string value.\n",
    "* StringIndexer encodes a string column of labels to a column of label indices. The indices are in [0, numLabels] ordered by label frequencies, so the most frequent label gets index 0. This is similar to label encoding in pandas.\n",
    "* The format and usage of StringIndexer is similar to VectorAssembler. Bot transform a DataFrame to introduce a new column with transformed data from one old col (for Stringindexer) or more than one column (for VectorAssembler)\n",
    ">* Note that we will use .fit(sdf).transform(sdf) for StringIndexer where as we will call only .transform(sdf) with VectorAssembler.\n",
    "* There are different ways to deal with categorical information\n",
    ">* We can separate out the \"Cruise_line\" categorical value into some dummy variables to have a single column 'yes\" or 'No' for every cruise line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "str_Indexer = StringIndexer(inputCol='Cruise_line', outputCol='Cruise_line_indexed')\n",
    "sdf_cruises_indexed = str_Indexer.fit(sdf_cruises).transform(sdf_cruises)\n",
    "sdf_cruises_indexed.printSchema()\n",
    "sdf_cruises.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize the numeric feature columns to get a unique 'features' column to pass to spark ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_input_cols = ['Cruise_line_indexed', 'Age',  'Tonnage',  'passengers',  'length',  'cabins',  'passenger_density']\n",
    "assembler = VectorAssembler(inputCols=feature_input_cols, outputCol='features')\n",
    "\n",
    "sdf_cruises_indexed_vec_data = assembler.transform(sdf_cruises_indexed)\n",
    "#The last call appends a vector column containing the merged data of featuree columns passed to assembler constructor\n",
    "\n",
    "sdf_cruises_indexed_vec_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_cruises_indexed_vec_data.select('features', 'crew').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = sdf_cruises_indexed_vec_data.select('features', 'crew')\n",
    "\n",
    "final_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "'''\n",
    "Default parameters are featuresCol='features', labelCol='label', predictionCol='prediction',\n",
    "\n",
    "The input DataFrame is having 'features' as vector feature column name and 'crew' as labelCol.\n",
    "Let us get the predicted data in a new column named 'prediction' by default.\n",
    "\n",
    "So in LinearRegression() constructor we need to adjust the labelCol alone. Default value is 'label', we need to change it to 'crew'\n",
    "For other params of constructor default is fine with us.\n",
    "'''\n",
    "\n",
    "lr_ship = LinearRegression(labelCol='crew')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ship_model_trained = lr_ship.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: {} Intercept: {}\".format(lr_ship_model_trained.coefficients,lr_ship_model_trained.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If the equation is Y = mX +c  '<b>m</b>' is the <b>coefficient</b>, whcih describes the relationship between X (the predictor or independent variable) and Y (the response or dependent variable) and '<b>c</b>' is the constant called <b>intercept</b>.\n",
    ">* A <b>+ve coefficient</b> indicates that as the predictor variable increases, the response variable also increases.\n",
    ">* A <b>-ve coefficient</b> indicates that as the predictor variable increases, the response variable decreases.\n",
    "* Tne coefficient value represents the mean change in the response given one unit change in the predictor.\n",
    "* Intercept is the value of response variable Y when the predictor value (X) is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### My Theory about coefficients and Intercept \n",
    "* If we can express the equation as below:\n",
    "* Y = $M_1X_1 + M_2X_2+M_3X_3+ ...$ + C = ($ \\sum_{i=1}^n M_i X_i$) + C \n",
    "* The Coefficients are  [$M_1, M_2, M_3, M_4, ...$] and Intercept is C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATE THE MODEL AGAINST THE TEST DATA AND PRINT THE COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = lr_ship_model_trained.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.meanAbsoluteError\n",
    "test_result.meanSquaredError\n",
    "test_result.r2\n",
    "test_result.rootMeanSquaredError\n",
    "test_result.residuals.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### If we get really good results, we need to do a reality check on the results\n",
    "* This is a real data on real ships obtained from US machine learning repostitoryi.e. U.C. Irvin\n",
    "* If we get very good results (a higher value for R-squared, see if any of the two feature columsn are highly co-related\n",
    ">* See if number of crew is highly co-related to number of passengers in board.\n",
    ">* or see if number of crew is highly co-related with number of cabins in hte ship\n",
    ">* We can use Pearson correlation to find this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_cruises.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr   # Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printHighlighted(\"corr('col1', 'col2') says how related are these two columns.\")\n",
    "sdf_cruises.select(corr('crew', 'passengers')).show()\n",
    "sdf_cruises.select(corr('crew', 'cabins')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_cruises.select(corr('crew', 'passenger_density')).show()\n",
    "sdf_cruises.select(corr('crew', 'length')).show()\n",
    "sdf_cruises.select(corr('crew', 'Age')).show()\n",
    "sdf_cruises.select(corr('crew', 'tonnage')).show()\n",
    "printHighlighted(\"Here we see that there is high correlation of 'crew' with 'passengers', 'tonnage' and 'cabins'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we see that, higer the number of passengers, ships need mroe crews and with lesser number of passengers lesser crew count will be needed.\n",
    "* Similarly higer  the numbe of cabins, even more higher will eb crew member count.\n",
    "* So a lot of features of ship itself indicates how many crew memer we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEPLOY THE MODEL / PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = test_data.select('features')\n",
    "unlabeled_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data = lr_ship_model_trained.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPARE THE PREDICTED RESUILT WITH THE EVALUATED TEST RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "test_data.createOrReplaceTempView(\"my_test_data\")\n",
    "predicted_data.createOrReplaceTempView(\"my_predicted_data\")\n",
    "\n",
    "input_output_df = sparkEx.sql(\"SELECT t.*, p.prediction, (t.crew - p.prediction) as difference  \\\n",
    "                                FROM my_test_data t, my_predicted_data p WHERE t.features==p.features\")\n",
    "input_output_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.residuals.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the error metrics\n",
    "* Refer: https://statisticsbyjim.com/glossary/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Coefficients and Intercept</u> (i.e. lr_mode.coefficients and lr_model.intercept)\n",
    "* If the equation is Y = mX +c  '<b>m</b>' is the <b>coefficient</b>, whcih describes the relationship between X (the predictor or independent variable) and Y (the response or dependent variable) and '<b>c</b>' is the constant called <b>intercept</b>.\n",
    ">* A <b>+ve coefficient</b> indicates that as the predictor variable increases, the response variable also increases.\n",
    ">* A <b>-ve coefficient</b> indicates that as the predictor variable increases, the response variable decreases.\n",
    "* Tne coefficient value represents the mean change in the response given one unit change in the predictor.\n",
    "* Intercept is the value of response variable Y when the predictor value (X) is zero.\n",
    "\n",
    "###### My Theory about coefficients and Intercept \n",
    "* If we can express the equation as below:\n",
    "* Y = $M_1X_1 + M_2X_2+M_3X_3+ ...$ + C = ($ \\sum_{i=1}^n M_i X_i$) + C \n",
    "* The Coefficients are  [$M_1, M_2, M_3, M_4, ...$] and Intercept is C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Residuals</u> and <u>RMS</u>\n",
    "* Residual is the difference between the observed value ($y_i$) and the mean value that the model predicts ($\\hat{y_i}$) for that observation.\n",
    "* $y_i$ is the observeed or actual value of dependent variable and $\\hat{y_i}$ is the predicted value (which falls on the regression line) for the same values of $x_i$\n",
    "* ($y_i-\\hat{y_i}$) or the errors are nothing but the elements of <b>residual</b>.\n",
    "* <i>Example:</i> When we predict on the feaures from the test_data (train_data vs test_data say in 70:30 proportion from final data of two column data frame features & label), the difference of our predictions from the evaluated test result on test_data was almost identical to the residuals of the test result.\n",
    "\n",
    "* <b>RMS</b> or <b>rootMeanSquaredError</b> = $\\sqrt{\\frac{1}{n}{\\sum{(y_i-\\hat{y_i})^2}}}$ which is same (as per <u>my theory</u>) as $\\sqrt{\\frac{1}{n}{\\sum{(residuals[i])^2}}}$\n",
    "* That means RMS is the square root of the average of squares of the residual elements\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>R-squared</u>\n",
    "* R-squared is the percentage of the Y (response variable) variation that is explained by a linear model.\n",
    "* It is always between 0 and 100% (i.e. between 0 and 1).\n",
    "* R-squared is a statistical measure of how close the data are to the fitted regression line.\n",
    "* It is also known as the <b>coefficient of determination</b>, or the <b>coefficient of multiple determination</b> for multiple regression.\n",
    "* In general, the <b>higher the R-squared, the better the model fits your data</b>. However, there are important conditions for this guideline that I discuss elsewhere.\n",
    "* If we select more training data, we will get a higher R-squared value. So [0.8, 0.2] will give better r2 value, but on the downside it will be a over-fit and it will reduce the test sample and hence we will not be able to valdate properly. Generally accepterd proportion is [0.7, 0.3]\n",
    "* Before you can trust the statistical measures for goodness-of-fit, like R-squared, you <b>should check the residual plots for unwanted patterns</b> that indicate biased results.\n",
    "Also check how the label is related to some of the crucial features of the ship itself, if we find the fit is better.\n",
    ">* Use Pearson correlation method to find the correlation\n",
    ">* sdf_cruises.select(corr('crew', 'passengers')) OR sdf_cruises.select(corr('crew', 'cabins'))  # <i>from pyspark.sql.functions import corr</i>\n",
    ">* If corr indicates high correlation by returning high value e.g. above 0.9, then be can assume that the model is good fit for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our exercise\n",
    "* .r2 (r squared) of 0.98 says that our model explains 98% of the variance in the data, which is very good\n",
    "* now that RMS and r squared are very good, we should think of double checking our data and double check the way we fitted our model to be more realistic\n",
    "\n",
    "* Compare the RMS values of mean and standard deviation of the final data (final_Data.describe().show()), if the RMS is much less than the stddev then it is good, so be suspicious.\n",
    "\n",
    "* If you get results very good with Linear Regression be siuspicious and check how you fit the model\n",
    "* Did we evaluate our model also on the training data which is already known to the model, which is a common mistake.\n",
    "\n",
    "######  points to note\n",
    "* we can expect more advanced and more complex models to have better fit, but if it is still a very good fit even with simple LinearRegression, double check the data and fitting way with a realistic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXTRA VALIDATIONS\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_cruises\n",
    "sdf_cruises_indexed\n",
    "sdf_cruises_indexed_vec_data\n",
    "lr_ship\n",
    "lr_ship_model_trained\n",
    "test_result\n",
    "predicted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.meanAbsoluteError\n",
    "test_result.meanSquaredError\n",
    "test_result.rootMeanSquaredError\n",
    "test_result.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
