{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TITANIC CLASSIFICATION EXAMPLE\n",
    "###### Project Requirements\n",
    "* There are a lot of examples on Titanic for different machine learning libraries\n",
    "* We wil predict which passengers survived Titanic crash based solely on passenger's features (age, cabin, how many children, male/female etc.)\n",
    "* Actual conclusion was peopple who are male or from a lower class such as third class tended not to survive.\n",
    "* People with higher classes (e.g. first class) or those who are female had  a higher likelihood of survival.\n",
    "* We will explore some better ways to deal with categorical data in a two-step process.\n",
    "* We will demomstrate a way on how to use pielines to set stages and build models that can be easily used again.\n",
    "* We will also deal with a lot of missign data.\n",
    "* Apache Spark Documentation: https://github.com/MingChen0919/learning-apache-spark\n",
    "\n",
    "#### Instructor uses DataBricks's notebook setup ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PipeLine result model fits less Where As manuall fit and transform fits better\n",
    "* Evaluation score from manual way is 0.88\n",
    "* Evaluation scopre using Pipeline is 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/nishita/exercises_udemy/tools/')\n",
    "from chinmay_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load titanic data from csv file into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_titanic = SparkSession.builder.appName('chin_titanic').getOrCreate()\n",
    "\n",
    "sdf_titanic = spark_titanic.read.csv('Logistic_Regression/titanic.csv', inferSchema=True, header=True)\n",
    "\n",
    "sdf_titanic.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the columns:\n",
    "* Sex -- Male / Female\n",
    "* SibSp -- indicates Siblings and Spouses they have onboarded\n",
    "* Parch -- indicates Parent and Children they have onboarded\n",
    "* Fare -- ticket price paid by the passengers\n",
    "* Cabin -- Cabin occupied by the passenger\n",
    "* Embarked -- It is the city name where the passnenger has embarked - actual string is a single letter\n",
    "<br/><br/>\n",
    "* PassengerID is just a index column and is not useful for our prediction\n",
    "<br/>\n",
    "\n",
    "###### We will select only th ecolumns that are useful to us\n",
    "\n",
    "* Now we sill select the columns 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'\n",
    "* We will think about 'Name' column late to decide whether he/she is a doctor or a mr or a mrs etc while usingg feature engineering.\n",
    "* What about 'Cabin'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7m\u001b[1mSelect desired columns and check null record counts\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printHighlighted('Select desired columns and check null record counts')\n",
    "sdf_titanic_myfields = sdf_titanic.select('Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked')\n",
    "\n",
    "# Fields with null: Age:177, Sex:2\n",
    "sdf_titanic.count()\n",
    "sdf_titanic_myfields.count()\n",
    "sdf_titanic_myfields.filter('Embarked is null OR Age is null').count()\n",
    "\n",
    "sdf_titanic_myfields.filter('Survived is null OR Pclass is null OR Sex is null OR Age is null '\n",
    "                            +' OR SibSp is null OR Parch is null OR Fare is null OR Embarked is null').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dealing with Null records\n",
    "* There are 177 records with null in 'Age' field and 2 records with null in 'Embarked' column\n",
    "* We will drop these 179 records from total of 891 titanic records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Drop Null records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_final_data = sdf_titanic_myfields.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the titanic dataframe there are two string fields, 'Sex' and 'Embarked', we need to convert them first to numeri (using StringIndexer) and then into a vector (using OneHotEncoder), and that vector will be part of final vectorized features column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dealing with String categorical fields\n",
    "* Convert the string field into numeric fields using StringIndexer with 0, 1, 2, ... upto number of unique values\n",
    "* Convert the numeric field into vector field using OneHotEncoder\n",
    "* <u>Example of StringIndexer and OneHotEncoder</u>\n",
    "* Suppose there are 3 unique values in a string field A, B, C\n",
    "* StringIndexer coverts the string column into numeric with values in [0, numLabels]\n",
    ">* most frequent label gets index 0 and next frequent gets 1 and so on as the default valeu of stringOrderType is 'frequencyDesc'\n",
    "<pre>\n",
    "<hr/>\n",
    "STRING:  A  B  C\n",
    "<hr/>\n",
    "NUMERIC: 0  1  2     (after StringIndexer)\n",
    "<hr/>\n",
    "A:   [1, 0, 0]       (after OneHotEncoder)\n",
    "B:   [0, 1, 0]\n",
    "C:   [0, 0, 1]\n",
    "</pre>\n",
    "* Say there are n categories or n unique values in the column then post OneHotEncoder each category will get a unique vector with n binary elements (o or 1) having at most single one-value.\n",
    "* Most frequent label will get first element as 1 and remaining n-1 elements as zeroes\n",
    "* Next frequent label will get second element as 1 and remaining (includign first one) will be zeroes  and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use StringIndexer to convert categorical values to categorical index which is a number in [0, numValues]\n",
    "#### Then use OneHotEncoder to convert that index into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler  #,  VectorIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex', outputCol='SexVec')\n",
    "\n",
    "embark_indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkIndex')\n",
    "embark_encoder = OneHotEncoder(inputCol='EmbarkIndex', outputCol='EmbarkVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Pclass', 'SexVec', 'Age', 'SibSp', 'Parch', 'Fare', 'EmbarkVec'], \n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logi_reg_titanic = LogisticRegression(featuresCol='features', labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Add to the Pipeline all the required stages (indexer, encoder,assembler and LogisticRegression model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(stages=[\n",
    "    gender_indexer, embark_indexer,\n",
    "    gender_encoder, embark_encoder,\n",
    "    assembler, logi_reg_titanic\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split the data into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_titanic_data, test_titanic_data = sdf_final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_titanic_data.count()\n",
    "test_titanic_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit the training data to the pipeline to get the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = my_pipeline.fit(train_titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Transform the test data using the trained model to get the prediction in the test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_model.transform(test_titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The transform() call on PipelineModel automatically calls the predicted column 'prediction'\n",
    "* The transform() call on PipelineModel automatically calls the predicted column 'prediction'\n",
    "* Hence when we evaluate() using BinaryClassificationEvaluator, we need to pass 'prediction' for the field rawPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.pipeline.PipelineModel"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fit_model)\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- SexIndex: double (nullable = false)\n",
      " |-- EmbarkIndex: double (nullable = false)\n",
      " |-- SexVec: vector (nullable = true)\n",
      " |-- EmbarkVec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# results.select('Survived', 'prediction').show()\n",
    "type(results)\n",
    "results.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Evaluate the test result using BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "bin_eval_raw = BinaryClassificationEvaluator(labelCol='Survived')\n",
    "\n",
    "bin_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The transform() call on PipelineModel automatically calls the predicted column 'prediction'\n",
    "* Hence when we evaluate() using BinaryClassificationEvaluator, we need to pass 'prediction' for the field rawPrediction of evaluator constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7m\u001b[1mASK INSTRUCTOR -- WHY ARE WE PASSING \"prediction\" IN PLACE OF \"rawPrediction\"\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "printHighlighted('ASK INSTRUCTOR -- WHY ARE WE PASSING \"prediction\" IN PLACE OF \"rawPrediction\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7m\u001b[1mEvaluating the predictions using BinaryClassificationEvaluator using metrics \"(NONE|areaUnderROC|areaUnderPR)\" \u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7780696744717305"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printHighlighted('Evaluating the predictions using BinaryClassificationEvaluator using metrics \"(NONE|areaUnderROC|areaUnderPR)\" ')\n",
    "bin_eval.evaluate(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It si wrong to use bin_eval_raw as it uses column 'rawPrediction' where as the pipelinemodel.transform outputs to field 'prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8519703026841803"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_eval_raw.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "multi_eval = MulticlassClassificationEvaluator(labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7m\u001b[1mEvaluating the predictions using MulticlassClassificationEvaluator using metrics \"(NONE|f1|weightedPrecision|weightedRecall|accuracy)\" \u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7844566780736993"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7844566780736993"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7907839837716972"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7872340425531915"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7872340425531915"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#                                                         (NONE|f1|weightedPrecision|weightedRecall|accuracy)')\n",
    "printHighlighted('Evaluating the predictions using MulticlassClassificationEvaluator using metrics \"(NONE|f1|weightedPrecision|weightedRecall|accuracy)\" ')\n",
    "multi_eval.evaluate(results)\n",
    "multi_eval.evaluate(results, {multi_eval.metricName: \"f1\"})\n",
    "multi_eval.evaluate(results, {multi_eval.metricName: \"weightedPrecision\"})\n",
    "multi_eval.evaluate(results, {multi_eval.metricName: \"weightedRecall\"})\n",
    "multi_eval.evaluate(results, {multi_eval.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
