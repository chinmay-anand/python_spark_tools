{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Consulting Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binary Customer Churn\n",
    "\n",
    "A marketing agency has many customers that use their service to produce ads for the client/customer websites. They've noticed that they have quite a bit of churn in clients. They basically randomly assign account managers right now, but want you to create a machine learning model that will help predict which customers will churn (stop buying their service) so that they can correctly assign the customers most at risk to churn an account manager. Luckily they have some historical data, can you help them out? Create a classification algorithm that will help classify whether or not a customer churned. Then the company can test this against incoming data for future customers to predict which customers will churn and assign them an account manager.\n",
    "\n",
    "The data is saved as customer_churn.csv. Here are the fields and their definitions:\n",
    "\n",
    "    Name : Name of the latest contact at Company\n",
    "    Age: Customer Age (Number of years customer is in business)\n",
    "    Total_Purchase: Total Ads Purchased\n",
    "    Account_Manager: Binary 0=No manager, 1= Account manager assigned\n",
    "    Years: Totaly Years as a customer (for this marketing agency)\n",
    "    Num_sites: Number of websites that use the service.\n",
    "    Onboard_date: Date that the name of the latest contact was onboarded\n",
    "    Location: Client HQ Address\n",
    "    Company: Name of Client Company\n",
    "    \n",
    "    * Churn - 1 customer has churned, 0 customer is still with the agency\n",
    "    \n",
    "Once you've created the model and evaluated it, test out the model on some new data (you can think of this almost like a hold-out set) that your client has provided, saved under new_customers.csv. The client wants to know which customers are most likely to churn given this data (they don't have the label yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/nishita/exercises_udemy/tools/')\n",
    "from chinmay_tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark1 = SparkSession.builder.appName('logi_proj_1').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the cSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_customers = spark1.read.csv('Logistic_Regression/customer_churn.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sdf_customers.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>summary</td>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Names</td>\n",
       "      <td>900</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Aaron King</td>\n",
       "      <td>Zachary Walsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Age</td>\n",
       "      <td>900</td>\n",
       "      <td>41.81666666666667</td>\n",
       "      <td>6.127560416916251</td>\n",
       "      <td>22.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Total_Purchase</td>\n",
       "      <td>900</td>\n",
       "      <td>10062.82403333334</td>\n",
       "      <td>2408.644531858096</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18026.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Account_Manager</td>\n",
       "      <td>900</td>\n",
       "      <td>0.4811111111111111</td>\n",
       "      <td>0.4999208935073339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Years</td>\n",
       "      <td>900</td>\n",
       "      <td>5.27315555555555</td>\n",
       "      <td>1.274449013194616</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Num_Sites</td>\n",
       "      <td>900</td>\n",
       "      <td>8.587777777777777</td>\n",
       "      <td>1.7648355920350969</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Location</td>\n",
       "      <td>900</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00103 Jeffrey Crest Apt. 205 Padillaville, IA ...</td>\n",
       "      <td>Unit 9800 Box 2878 DPO AA 75157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Company</td>\n",
       "      <td>900</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Abbott-Thompson</td>\n",
       "      <td>Zuniga, Clark and Shaffer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Churn</td>\n",
       "      <td>900</td>\n",
       "      <td>0.16666666666666666</td>\n",
       "      <td>0.3728852122772358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                    1                   2  \\\n",
       "summary          count                 mean              stddev   \n",
       "Names              900                 None                None   \n",
       "Age                900    41.81666666666667   6.127560416916251   \n",
       "Total_Purchase     900    10062.82403333334   2408.644531858096   \n",
       "Account_Manager    900   0.4811111111111111  0.4999208935073339   \n",
       "Years              900     5.27315555555555   1.274449013194616   \n",
       "Num_Sites          900    8.587777777777777  1.7648355920350969   \n",
       "Location           900                 None                None   \n",
       "Company            900                 None                None   \n",
       "Churn              900  0.16666666666666666  0.3728852122772358   \n",
       "\n",
       "                                                                 3  \\\n",
       "summary                                                        min   \n",
       "Names                                                   Aaron King   \n",
       "Age                                                           22.0   \n",
       "Total_Purchase                                               100.0   \n",
       "Account_Manager                                                  0   \n",
       "Years                                                          1.0   \n",
       "Num_Sites                                                      3.0   \n",
       "Location         00103 Jeffrey Crest Apt. 205 Padillaville, IA ...   \n",
       "Company                                            Abbott-Thompson   \n",
       "Churn                                                            0   \n",
       "\n",
       "                                               4  \n",
       "summary                                      max  \n",
       "Names                              Zachary Walsh  \n",
       "Age                                         65.0  \n",
       "Total_Purchase                          18026.01  \n",
       "Account_Manager                                1  \n",
       "Years                                       9.15  \n",
       "Num_Sites                                   14.0  \n",
       "Location         Unit 9800 Box 2878 DPO AA 75157  \n",
       "Company                Zuniga, Clark and Shaffer  \n",
       "Churn                                          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_customers.filter('Names is null OR Age is null OR Total_Purchase is null OR Account_Manager is null '\n",
    "                     +'OR Years is null OR Num_Sites is null OR Onboard_date is null '\n",
    "                     +'OR Location is null OR Company is null OR Churn is null').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_customers.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Age', 'Total_Purchase', 'Account_Manager', 'Years', 'Num_Sites'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_customers.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vectorize the numeric columns using VectorAssembler into a 'features' column to be processed by Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=['Age', 'Total_Purchase', 'Account_Manager', 'Years', 'Num_Sites'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf2 = assembler.transform(sdf_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n",
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf2.printSchema()\n",
    "sdf_customers.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pick the vectorized 'features' column along with the label column ('Churn'), without any null records, as our final data.\n",
    "* Split that final data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = sdf2.select('features', 'Churn')\n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|              Churn|\n",
      "+-------+-------------------+\n",
      "|  count|                635|\n",
      "|   mean|0.16377952755905512|\n",
      "| stddev|0.37036713206489047|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|              Churn|\n",
      "+-------+-------------------+\n",
      "|  count|                265|\n",
      "|   mean|0.17358490566037735|\n",
      "| stddev| 0.3794687990708427|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate a LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr_churn = LogisticRegression(labelCol='Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit or train the model to our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.classification.LogisticRegressionModel"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_churn_model = lr_churn.fit(train_data)\n",
    "type(fitted_churn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just for our curiosity check/explore the summary of the trained model.\n",
    "* Compare the mean and standarddeviation of the actual lavel ('Churn') and the predicted label ('oprediction') in the \"predictions\" dataframe in the summary field of the trained model or fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              Churn|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                635|                635|\n",
      "|   mean|0.16377952755905512|0.11811023622047244|\n",
      "| stddev|0.37036713206489047| 0.3229930322310653|\n",
      "|    min|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitted_churn_model.summary.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is better to do some evaluation of our trained model.\n",
    "* We will do ou revaluation matrix against MLlib evaluation and our test data.\n",
    "* Evaluate the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_and_labels = fitted_churn_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.classification.BinaryLogisticRegressionSummary"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|Churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[29.0,9617.59,0.0...|    0|[4.33619789368198...|[0.98708284747953...|       0.0|\n",
      "|[29.0,11274.46,1....|    0|[4.32026483436165...|[0.98687811163184...|       0.0|\n",
      "|[29.0,13255.05,1....|    0|[3.93216453654270...|[0.98077562177472...|       0.0|\n",
      "|[30.0,10183.98,1....|    0|[2.76154719759367...|[0.94056218902118...|       0.0|\n",
      "|[30.0,10744.14,1....|    1|[1.70261087076890...|[0.84587542210017...|       0.0|\n",
      "|[31.0,5387.75,0.0...|    0|[2.66119093942064...|[0.93469739698469...|       0.0|\n",
      "|[31.0,8688.21,0.0...|    0|[6.51122643621272...|[0.99851555154657...|       0.0|\n",
      "|[32.0,5756.12,0.0...|    0|[4.28996319998580...|[0.98647986954864...|       0.0|\n",
      "|[32.0,6367.22,1.0...|    0|[2.88191149568013...|[0.94694497958478...|       0.0|\n",
      "|[32.0,9036.27,0.0...|    0|[-0.3122255690392...|[0.42257159587421...|       1.0|\n",
      "|[32.0,13630.93,0....|    0|[1.94931643913282...|[0.87537208732844...|       0.0|\n",
      "|[33.0,5738.82,0.0...|    0|[4.59831252924318...|[0.99003155812643...|       0.0|\n",
      "|[33.0,8556.73,0.0...|    0|[3.62801970798945...|[0.97411888261603...|       0.0|\n",
      "|[33.0,12115.91,1....|    0|[2.28097256641968...|[0.90728888746034...|       0.0|\n",
      "|[33.0,12249.96,0....|    0|[5.20267754052615...|[0.99452829096874...|       0.0|\n",
      "|[33.0,12638.51,1....|    0|[3.72538283692710...|[0.97646345112497...|       0.0|\n",
      "|[33.0,13314.19,0....|    0|[2.62795448426722...|[0.93263915690937...|       0.0|\n",
      "|[34.0,5447.16,1.0...|    0|[3.44905278070208...|[0.96920287998075...|       0.0|\n",
      "|[34.0,9401.99,1.0...|    0|[1.06620765324221...|[0.74387504760004...|       0.0|\n",
      "|[34.0,10466.56,0....|    0|[5.33970432228264...|[0.99522561515162...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the BinaryClassificationEvaluator to check the area under the curve\n",
    "\n",
    "* Evaluate our model predications using BinaryClassificationEvaluator to find area under curse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Churn')\n",
    "\n",
    "# BinaryClassificationEvaluator(labelCol='Churn')\n",
    "# The parameter \"rawPredictionCol\" picks by default column name as 'rawPRediction', which is wrong here. WHY? Ask Instructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055390113162597"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[7m\u001b[1mNOTE: a value of 0.5 is equivalent to doing a \"random guess\" \n",
      "Here our result is not bad but not that great as well.\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Using 'prediction' column for rawPrediction field (as used by Instructor)\n",
    "bin_eval.evaluate(predictions_and_labels.predictions)\n",
    "printHighlighted('NOTE: a value of 0.5 is equivalent to doing a \"random guess\" \\nHere our result is not bad but not that great as well.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now predict on a new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To predict on a new data we will train our model on the entire historical data set (not only training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fitted_model = lr_churn.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_newcust = spark1.read.csv('Logistic_Regression/new_customers.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
      "|         Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|       Onboard_date|            Location|         Company|\n",
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
      "| Andrew Mccall|37.0|       9935.53|              1| 7.71|      8.0|2011-08-29 18:37:54|38612 Johnny Stra...|        King Ltd|\n",
      "|Michele Wright|23.0|       7526.94|              1| 9.28|     15.0|2013-07-22 18:19:54|21083 Nicole Junc...|   Cannon-Benson|\n",
      "|  Jeremy Chang|65.0|         100.0|              1|  1.0|     15.0|2006-12-11 07:48:13|085 Austin Views ...|Barron-Robertson|\n",
      "|Megan Ferguson|32.0|        6487.5|              0|  9.4|     14.0|2016-10-28 05:32:13|922 Wright Branch...|   Sexton-Golden|\n",
      "|  Taylor Young|32.0|      13147.71|              1| 10.0|      8.0|2012-03-20 00:36:46|Unit 0789 Box 073...|        Wood LLC|\n",
      "| Jessica Drake|22.0|       8445.26|              1| 3.46|     14.0|2011-02-04 19:29:27|1148 Tina Straven...|   Parks-Robbins|\n",
      "+--------------+----+--------------+---------------+-----+---------+-------------------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_newcust.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vectorize the numeric columns into a 'features' column\n",
    "* Confirm that the results has a 'features' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_test_newcust = assembler.transform(sdf_newcust)\n",
    "sdf_test_newcust.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then instead of earlier test data we will evaluate on the new data.\n",
    "* We will now predict the 'Churn' using transform() call to the all_data fitted model, this adds a 'prediction' column to the result. In fact it adds the 3 columns rasPredition, probability and Churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = final_fitted_model.transform(sdf_test_newcust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|         Names|prediction|\n",
      "+--------------+----------+\n",
      "| Andrew Mccall|       0.0|\n",
      "|Michele Wright|       1.0|\n",
      "|  Jeremy Chang|       1.0|\n",
      "|Megan Ferguson|       1.0|\n",
      "|  Taylor Young|       0.0|\n",
      "| Jessica Drake|       1.0|\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results.select('Names', 'prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
