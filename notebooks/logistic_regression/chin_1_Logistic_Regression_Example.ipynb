{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "* Logistic Regression is a classificaiton algorithm, where we try to predict discrete categories\n",
    "* Linear Regresssion is used for predicting continuous data\n",
    "* whereas Logistic Regression used for classification or grouping into discrete categories (in contrast to word \"regression\" pointing at continuous data)\n",
    "* For understanding concepts behind the evaluation methods and metrics behind classificaiton\n",
    ">* REFER sections 4 - 4.3 in Introduction to Statistical Learning by Gareth James\n",
    "* EXAMPLES of Ninary classification: (classification between two classes)\n",
    ">* \"Spam\" vs \"Ham\" emails (Finding a mail whether it is bad (ham) or good (ham)\n",
    ">* Loan Default (Yes/No) - Finding whether a customer will default loan or not\n",
    ">* Disease Diagnosis - e.g. whether a patient will be diagnosed with cancer or not based on certain body parameters\n",
    "* To classify into one of the two classes we need a function that fits binary categorical data. We can not use Linear Regression as a lot of poitns will not fit into it.\n",
    "* There is a funciton called \"Sigmoid Function\" that returns value between 0 and 1 for any input value.\n",
    "* So to do binarry classification (say between class 0 and class 1) we can follow the below appraoch:\n",
    ">1. We take the results from Linear Regression.\n",
    ">2. Pass the linear regression result into Sigmoid Function to get values between 0 and 1.\n",
    ">3. Then we set the cut-off point at 0.5\n",
    ">4. Anything below the cut-off points results in class 0 and anything above will be classified as class 1.\n",
    "* Below block explains in brief how Sigmoid Function works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Function (aka Logistic)\n",
    "\n",
    "# $\\phi(x) = \\frac{e^x}{e^x+1}  =  \\frac{1}{1+e^{-x}}$\n",
    "This sigmoid function always returns values between 0 to 1 for any value of x\n",
    "* So we can take our Linear Regression solution and place it into the Sigmoid Function\n",
    "\n",
    "* <h6 style=\"display: inline\"></h6>Linear Model\n",
    "<h2 style=\"display: inline\">$ y = b_0 + b_1x$</h2>\n",
    "\n",
    "* <h6 style=\"display: inline\"></h6>Logistic Model\n",
    "<h2 style=\"display: inline\">$\\phi(y) = \\frac{1}{1+e^{-y}} = \\frac{1}{1+e^{-(b_0+b_1x)}}$</h2>\n",
    "* So no matter what is the result of Linear Regression, the result will always be between 0 to 1\n",
    "* This results in a probability from 0 to 1 belonging to one class.\n",
    "* Then we set the cut-off point at 0.5, anything below it results in class 0 and anything above will be classified as class 1.\n",
    "* ![](./logistic_regression_steps.png)\n",
    "* <table><tr>\n",
    "    <td><img src=\"logistic_regression_steps.png\" width=\"500\" /></td>\n",
    "    <td><img src=\"confusiton_matrix_metrics_ratios.png\" width=\"400\" /></td>\n",
    "  </tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Metrics in Logistic Regression\n",
    "* The metrics is measured by using a confusion matrix.\n",
    "* Accuracy is $\\frac{TP + TN}{Total Cases}$\n",
    "* Misclassification rate is $\\frac{FP + FN}{Total Cases}$\n",
    "* Type-I error = False Positives, Tyupe-II error = False Negatives\n",
    "* Legends:  T-True, F-False, P-Positive, N-Negative\n",
    "* Sensitivity or Recall = $\\frac{True Positives}{Conditional Positives}$\n",
    "<img src=\"metrics_from_confusion_matrix.png\" width=\"700\" height=\"100\" />\n",
    "* Receiver Operator Curve (ROC Curve) is the plot between Sensitivity (y-axis) vs 1-Specificiity (x-axis) i.e. graph of True positive vs False positive rate\n",
    ">* Area under the curve is a metric for how well the model fit the data.\n",
    ">* Above the red random guess lime means our model is performing better than random guess. If below then model is performing worse than the random guess. <img src=\"roc_curve_plot.png\" width=\"500\" height=\"100\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluators\n",
    "* Evaluation DataFrame - Evaluation DataFrames are the dataframes returned by model.evaluate(test_data) method\n",
    "* Evaluators are similar to Machine Learning Algorithm objects but are designed to take evaluation dataframes.\n",
    "* Evaluators being experimental, we should be cautious while using them on production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
