{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To break a cell into two press \"SHIFT+CTRL+MINUS\" with cursor at the split point during editing the cell\n",
    "###### To merget wo cells press \"SHIFT+M\" while the cell is in view mode (not editing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online ML repositories\n",
    "*. https://towardsdatascience.com/top-sources-for-machine-learning-datasets-bb6d0dc3378b\n",
    "1. Goole's Datasets Search Engine (https://datasetsearch.research.google.com/)\n",
    "2. Kaggle  (https://www.kaggle.com/datasets)\n",
    "3. Amazon  (https://registry.opendata.aws/)\n",
    "4. UC Irvine ML Repository (https://archive.ics.uci.edu/ml/index.php)\n",
    ">* https://archive.ics.uci.edu/ml/datasets.php\n",
    "5. Visual Data on computer vision (https://www.visualdata.io/)\n",
    "6. Carnegi Melon Datasets (https://guides.library.cmu.edu/machine-learning/datasets)\n",
    "7. Microsoft Datasets (https://msropendata.com/)\n",
    "8. Government Datasets (EU, US, NZ, India, Ireland)\n",
    "9. Awesome Public Datasets at GitHub (https://github.com/awesomedata/awesome-public-datasets)\n",
    "10. LionBridge Dataset (https://lionbridge.ai/datasets/)\n",
    "4. https://elitedatascience.com/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying multiple aggregates on a groupby object for a datafrrame of multiple numeric columns\n",
    "* We can apply multiple aggregates to a groupby object of a DataFrame with one aggregate per each numeric column of the DataFrame\n",
    "* Syntax:\n",
    ">* grpByYr.agg({'colNm1':'aggFn1','colNm2':'aggFn2', 'colNm3':'aggFn3'}).show()\n",
    ">* grpByYr.agg({'Open':'max','Close':'min', 'Volume':'avg'}).show()\n",
    "* If a specific column is repeated for more than one aggregate functions, then the last aggregate function is operated for the column, all peevious ones on the same column are ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ###### Example of aggregate funtions on the groupBy of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSessnStock = SparkSession.builder.appName(\"chin_date\").getOrCreate()\n",
    "my_csv_app_stocks = \"test_data/appl_stock.csv\"\n",
    "sdf_stock = sparkSessnStock.read.csv(my_csv_app_stocks, header=True, inferSchema=True)\n",
    "\n",
    "from pyspark.sql.functions import year, month\n",
    "sdf_stock2 = sdf_stock.withColumn('Year', year('Date')).withColumn('Month', month('Date'))\n",
    "sdf_stock2.printSchema()\n",
    "\n",
    "grpYr = sdf_stock2.groupBy('Year')\n",
    "grpYr.agg({'Open':'max','Close':'min', 'Volume':'avg'}).show()\n",
    "\n",
    "grpMn = sdf_stock2.groupBy('Month')\n",
    "grpMn.agg({'Open':'max','Close':'min', 'Volume':'avg'}).orderBy('Month').show()\n",
    "#grpMn.agg({'Open':'max','Close':'min', 'Volume':'avg'}).orderBy(sdf_stock2['Month'].desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESSION EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Regression models like Linear Regression predict continuous values\n",
    "* Categorical values are Classification models which categorize the items into distinct categories\n",
    "* Metrics like \"accuracy\" or \"recall\" are not useful for regression problems\n",
    "* Evaluation metrics for Regression are designed for continuous values, some of these are:\n",
    ">* Mean Absolute Error ($\\frac{1}{n} \\sum_{i=1}^n |y_i-\\hat{y_i}|$)\n",
    ">* Mean Squared Error ($\\frac{1}{n} \\sum_{i=1}^n (y_i-\\hat{y_i})^2$)\n",
    ">* Root Mean Squared Error ($\\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i-\\hat{y_i})^2}$)\n",
    ">* R Squared Values\n",
    ">> R square (or .r2) is basically statistical property of our model, it is not a evaluation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE):\n",
    "\n",
    "* ### $\\frac{1}{n} \\sum_{i=1}^n |y_i-\\hat{y_i}|$\n",
    "* This is the mean of the absolute value of errors i.e. just the average error\n",
    "* Example: If we are predicting the price of a house based on its features then MAE says on average how far we are off on hte hous price.\n",
    "* N.B. The error is the difference between the predicted label ($\\hat{y_i}$), which is on the regression line) and the actual label ($y_i$) for a value of predictor x i.e. on the same vertical line. If the actual point falls below the regression line then this difference will be negateive and we cake the absolute value as the negative ones will cancel out the positive values giving wrong result. Hence we take the absolute values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error (MSE):\n",
    "\n",
    "* ### $\\frac{1}{n} \\sum_{i=1}^n (y_i-\\hat{y_i})^2$\n",
    "* This is the mean of the squared errors i.e. just the average error\n",
    "* Being squared, larger errors are noted more than with MAE. Hence MSE is more popular than MAE.\n",
    "* If the error i.e difference between actual value($y_i$) and predicted value ($\\hat{y_i}$) is more, then the difference is punished more and we take the average we can see that error more. MSE is more popu;lar as ti takes into account when we are off by very large amount.\n",
    "* The issue will be in unit, which is a squared unit here, so we take suare root of MSE  to get RMSE (Root Mean Absolute Error)\n",
    "* N.B. The error is the difference between the predicted label ($\\hat{y_i}$), which is on the regression line) and the actual label ($y_i$) for a value of predictor x i.e. on the same vertical line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Absolute Error (RMSE):\n",
    "\n",
    "* ### $\\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i-\\hat{y_i})^2}$\n",
    "* This is root of MSE i.e. root of the mean of the squared errors\n",
    "It is most popular as its unit is same as that of y, and at the same time errors are punishedd more for higher difference.\n",
    "* Being squared, larger errors are punished more than with MAE. Hence MSE is more popular than MAE.\n",
    "* If the error i.e difference between actual value($y_i$) and predicted value ($\\hat{y_i}$) is more, then the difference is punished more and we take the average we can see that error more. MSE is more popu;lar as ti takes into account when we are off by very large amount.\n",
    "* N.B. The error is the difference between the predicted label ($\\hat{y_i}$), which is on the regression line) and the actual label ($y_i$) for a value of predictor x i.e. on the same vertical line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R Squared Values (R2)\n",
    "\n",
    "* R squared values are also known as \"Coefficient of determination\"\n",
    "* It is not an error metric, more of a statistical measure of our regression model.\n",
    "    * It is the proportion of the variance in the dependent variable ($y_i$) that is predictable from the independent variable(s), i.e. $x1_i, x2_i etc$\n",
    "* This tells how much variance our model accounts for.\n",
    "* Its values lie between 0 and 1 (i.e between 0% to 100%)\n",
    "* Example: if the value is 0.9 means it explains 90% of the variance of the data.\n",
    "* Adjusted R squared value is a different way of obtaininng $R^2$\n",
    "    * During machine learning if we get a negative value for $R^2$, then it is calculated using a different method.\n",
    "* When we want to compare models to each other, we should use Adjsuted $R^2$ not a normal one.\n",
    "    * Simple numerical comparison fo $R*2$ is nto enough a thorough analysis is needed.\n",
    "* We can use this to understand our model better or compare models but it is not the sole source of evaluating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT: Linear Regression Example Code Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: \n",
    "* ###### Here we are trying to predict a customer's Total Amount Expenditure (a continuous money value)\n",
    "* ###### We will then convert the realistic data into a format acceptable by Spark's MLlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
